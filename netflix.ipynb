{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "show_id           0\n",
      "type              0\n",
      "title             0\n",
      "director        473\n",
      "cast            190\n",
      "country         219\n",
      "date_added        3\n",
      "release_year      0\n",
      "rating            3\n",
      "duration          0\n",
      "listed_in         0\n",
      "description       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "hotstar_data = pd.read_csv(r\"C:\\Users\\Abinaya\\OneDrive\\Desktop\\Netflix-Prime-Hotstar-Dashboard-Power-BI-main\\dataset\\disney_plus_titles.csv\")\n",
    "\n",
    "print(hotstar_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled missing 'director' values:  0\n",
      "Filled missing 'cast' values:  0\n",
      "Filled missing 'country' values:  0\n",
      "Filled missing 'date_added' values:  0\n",
      "Filled missing 'rating' values:  0\n"
     ]
    }
   ],
   "source": [
    "# 1. Fill missing 'director' with 'Unknown'\n",
    "hotstar_data['director'] = hotstar_data['director'].fillna('Unknown')\n",
    "\n",
    "# 2. Fill missing 'cast' with 'Unknown'\n",
    "hotstar_data['cast'] = hotstar_data['cast'].fillna('Unknown')\n",
    "\n",
    "# 3. Fill missing 'country' with 'Unknown'\n",
    "hotstar_data['country'] = hotstar_data['country'].fillna('Unknown')\n",
    "\n",
    "# 4. Fill missing 'date_added' with the most common date (mode)\n",
    "hotstar_data_date_added = hotstar_data['date_added'].mode()[0]\n",
    "hotstar_data['date_added'] = hotstar_data['date_added'].fillna(hotstar_data_date_added)\n",
    "\n",
    "# 5. Fill missing 'rating' with the most common rating\n",
    "netflix_rating = hotstar_data['rating'].mode()[0]\n",
    "hotstar_data['rating'] = hotstar_data['rating'].fillna(netflix_rating)\n",
    "\n",
    "\n",
    "\n",
    "# Print statements to verify that the changes have been applied correctly\n",
    "print(\"Filled missing 'director' values: \", hotstar_data['director'].isnull().sum())\n",
    "print(\"Filled missing 'cast' values: \", hotstar_data['cast'].isnull().sum())\n",
    "print(\"Filled missing 'country' values: \", hotstar_data['country'].isnull().sum())\n",
    "print(\"Filled missing 'date_added' values: \", hotstar_data['date_added'].isnull().sum())\n",
    "print(\"Filled missing 'rating' values: \", hotstar_data['rating'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   duration  duration_minutes\n",
      "0    23 min                23\n",
      "1    91 min                91\n",
      "2    23 min                23\n",
      "3    41 min                41\n",
      "4  1 Season               125\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Function to convert duration to minutes\n",
    "def convert_duration_to_minutes(duration):\n",
    "    if isinstance(duration, float) and np.isnan(duration):\n",
    "        # Handle NaN values (leave them as NaN for now)\n",
    "        return np.nan\n",
    "    elif 'Season' in duration:\n",
    "        # Extract the number of seasons and multiply by 125\n",
    "        seasons = int(duration.split(' ')[0])\n",
    "        return seasons * 125\n",
    "    else:\n",
    "        # Extract the numeric part of the minutes\n",
    "        return int(duration.split(' ')[0])\n",
    "\n",
    "# Apply the function to the duration column\n",
    "hotstar_data['duration_minutes'] = hotstar_data['duration'].apply(convert_duration_to_minutes)\n",
    "\n",
    "\n",
    "\n",
    "# Verify the result\n",
    "print(hotstar_data[['duration', 'duration_minutes']].head())\n",
    "\n",
    "# Drop the original 'duration' column if necessary\n",
    "hotstar_data.drop('duration', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "show_id             0\n",
      "type                0\n",
      "title               0\n",
      "director            0\n",
      "cast                0\n",
      "country             0\n",
      "date_added          0\n",
      "release_year        0\n",
      "rating              0\n",
      "listed_in           0\n",
      "description         0\n",
      "churn               0\n",
      "duration_minutes    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(hotstar_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_churn_column(data):\n",
    "    # Define churn criteria\n",
    "    churn_condition = data['rating'].isin(['TV-PG', 'TV-14', 'TV-13'])  # Add more criteria as needed\n",
    "    data['churn'] = np.where(churn_condition, 1, 0)  # 1 for churn, 0 for no churn\n",
    "    return data\n",
    "\n",
    "# Apply the function to the netflix data\n",
    "hotstar_data = create_churn_column(hotstar_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Churn column saved to Excel file successfully.\n"
     ]
    }
   ],
   "source": [
    "output_file_path = r\"C:\\Users\\Abinaya\\OneDrive\\Documents\\ABI\\BI Lab\\Netflix-Prime-Hotstar-Dashboard-Power-BI-main\\dataset\\updated_hotstar_data.xlsx\"\n",
    "hotstar_data.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(\"Churn column saved to Excel file successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Confusion Matrix:\n",
      "[[227   0]\n",
      " [  0  63]]\n",
      "Random Forest Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       227\n",
      "           1       1.00      1.00      1.00        63\n",
      "\n",
      "    accuracy                           1.00       290\n",
      "   macro avg       1.00      1.00      1.00       290\n",
      "weighted avg       1.00      1.00      1.00       290\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "features = hotstar_data[['rating', 'duration_minutes']]  # Add more relevant features if needed\n",
    "labels = hotstar_data['churn']\n",
    "\n",
    "# Convert categorical variables into dummy/indicator variables\n",
    "features = pd.get_dummies(features, columns=['rating'], drop_first=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Print the confusion matrix\n",
    "\n",
    "print(\"Random Forest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(rf_model, 'hotstar_rf_model.pkl')\n",
    "print(\"Random Forest model saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated DataFrame with predicted churn saved to Excel file successfully.\n"
     ]
    }
   ],
   "source": [
    "hotstar_data['predicted_churn'] = rf_model.predict(features)  # Make predictions on the original dataset\n",
    "\n",
    "# Save the updated DataFrame with the predicted churn to a new Excel file\n",
    "output_file_path = r\"C:\\Users\\Abinaya\\OneDrive\\Documents\\ABI\\BI Lab\\Netflix-Prime-Hotstar-Dashboard-Power-BI-main\\dataset\\updated_hotstar_data_with_predictions.xlsx\"\n",
    "hotstar_data.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(\"Updated DataFrame with predicted churn saved to Excel file successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
